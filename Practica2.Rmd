---
title: "Practica2"
author: "Anali y David"
date: "2026-01-12"
output: html_document
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r carga_libs, include=FALSE}
library(httr)
library(XML)
library(ggplot2)
library(rvest)
```

## Practica2 

### Ejercicio 1
Queremos programar un programa de tipo web scrapping con el que podamos obtener 
una página web, mediante su URL, y poder analizar su contenido HTML con tal de extraer 
datos e información específica. 

La URL elegida es la siguiente.URL: https://www.mediawiki.org/wiki/MediaWiki

Lectura base: 

```{r get_webpage, include=TRUE}
html <- read_html("https://www.mediawiki.org/wiki/MediaWiki")
class(html)
print(html)
```

### Ejercicio 2
Analizar el contenido de la web, buscando el título de la página (que en HTML 
se etiqueta como “title”). 
En las cabeceras web encontramos información como el título, los ficheros de 
estilo visual, y meta-información como el nombre del autor de la página, una 
descripción de esta, el tipo de codificación de esta, o palabras clave que indican 
qué tipo de información contiene la página. Una vez descargada la página, y 
convertida a un formato analizable (como XML), buscaremos los elementos de 
tipo “title”. P.e. “<title>Titulo de Página</title>”. 

```{r get_title, include=TRUE}
url <- "https://www.mediawiki.org/wiki/MediaWiki"

page <- read_html(url)

title <- page %>%
  html_element("title") %>%
  html_text(trim = TRUE)

title
```

### Ejercicio 3
Analizar el contenido de la web, buscando todos los enlaces (que en HTML se 
etiquetan como “a”), buscando el texto del enlace, así como la URL. 
Vamos a extraer, usando las funciones de búsqueda XML, todos los enlaces que 
salen de esta página con tal de listarlos y poder descargarlas más tarde. Sabemos 
que estos son elementos de tipo “<a>”, que tienen el atributo “href” para indicar 
la URL del enlace. P.e. “<a href = ‘enlace’>Texto del Enlace</a>”. Del enlace 
nos quedaremos con la URL de destino y con el valor del enlace (texto del 
enlace). 

```{r get_ahref, include=TRUE}
url <- "https://www.mediawiki.org/wiki/MediaWiki"
page <- read_html(url)
links <- page %>%
  html_elements("a") %>%
  html_attr("href")
links
```

### Ejercicio 4
Generar una tabla con cada enlace encontrado, indicando el texto que
acompaña el enlace, y el número de veces que aparece un enlace con ese
mismo objetivo.
En este paso nos interesa reunir los datos obtenidos en el anterior paso.
Tendremos que comprobar, para cada enlace, cuantas veces aparece. 

```{r create_table, include=TRUE}

```
